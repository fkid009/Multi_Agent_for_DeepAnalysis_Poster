{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "805a2a61-bc0b-42b7-b626-244b4b61d69b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f05fde-bbc4-420c-9351-264ef6df3091",
   "metadata": {},
   "source": [
    "# 아이디어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76911bbb-3099-46b6-8486-cb55bb1b0c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI 에이전트를 사용하여 연구 포스터 이미지 내의 다양한 그래프를 자동을 탐지하고 인식한 뒤 내용을 통합적으로 분석하는 시스템 개발"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5298809d-c48d-4b36-9ab6-af04ccce96e7",
   "metadata": {},
   "source": [
    "핵심 구성 요소\n",
    "\n",
    "1. 포스터 이미지 입력\n",
    "\n",
    "- 전체 연구 포스터를 하나의 이미지 파일로 입력받음\n",
    "\n",
    "2. 시각 요소 탐지\n",
    "\n",
    "- 포스터 내에 포함된 그래프, 표, 도식, 텍스트를 각각 영역별로 분할\n",
    "\n",
    "- → 이를 위해 object detection 모델 (e.g. YOLO, DETR) 혹은 OCR 기반 레이아웃 분석 (e.g. LayoutLMv3) 활용 가능\n",
    "\n",
    "3. 그래프 종류 및 내용 인식\n",
    "\n",
    "- 그래프가 선형인지 막대형인지 등 종류를 분류\n",
    "\n",
    "- 그래프 이미지에서 축 정보, 범례, 데이터 포인트 추출\n",
    "\n",
    "- → computer vision + OCR 기반 그래프 파싱 (e.g. PlotQA, ChartOCR, DePlot 등 사용 가능)\n",
    "\n",
    "4. 텍스트와의 연관 분석\n",
    "\n",
    "- 그래프 주변 텍스트(캡션, 설명 등)와 연결하여 의미 해석\n",
    "\n",
    "- → 텍스트-이미지 alignment 필요 (e.g. multimodal transformer or cross attention)\n",
    "\n",
    "5. 통합 분석 및 요약\n",
    "\n",
    "- 포스터 내 모든 그래프와 텍스트 정보를 연결하여 연구 주제나 결론 도출\n",
    "\n",
    "- → 멀티에이전트 구조로 각 파트별 전문 AI를 둘 수도 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6473e89-9e07-400c-b42d-87f6ebb2e82c",
   "metadata": {},
   "source": [
    "# 멀티에이전트 설계아이디어\n",
    "| 에이전트 이름          | 역할                                  |\n",
    "| ---------------- | ----------------------------------- |\n",
    "| **레이아웃 인식 에이전트** | 포스터 내 시각적 영역 분할 (텍스트 vs 그래프 vs 표 등) |\n",
    "| **그래프 인식 에이전트**  | 그래프 이미지 종류 분류 및 데이터 추출              |\n",
    "| **텍스트 연관 에이전트**  | 그래프와 주변 설명 텍스트 매핑                   |\n",
    "| **분석 요약 에이전트**   | 그래프 간 관계 분석 및 전체 요약 생성              |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8801068-03f5-4221-ac2d-5fdf9747ffae",
   "metadata": {},
   "source": [
    "# 스택"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc3ec10-e001-4132-ba7a-b5417d8755ae",
   "metadata": {},
   "source": [
    "- 그래프 탐지 및 인식: DePlot, ChartOCR, PlotQA\n",
    "\n",
    "- 텍스트 인식: Tesseract OCR, PaddleOCR, LayoutLMv3\n",
    "\n",
    "- 멀티모달 분석: BLIP-2, GPT-4V, Kosmos-2, LLaVA\n",
    "\n",
    "- 멀티 에이전트 프레임워크: LangGraph, CrewAI, Autogen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed4bc05-dc03-49e5-aa95-ddeee233478c",
   "metadata": {},
   "source": [
    "# Demo Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9738f0-78cf-4b61-9a6d-fbce89d48169",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph_swarm import create_handoff_tool, create_swarm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36cd4dcb-735b-4bf4-be1b-057b0c128583",
   "metadata": {},
   "source": [
    "## Layout Detect Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "898664a5-d25d-4e81-ac6c-7e20f4387b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_layout():\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8a23b66-a38d-4683-94b3-67fcb14981cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layout(image_path: str) -> dict:\n",
    "    \"\"\"Analyze a research poster image and return layout components such as text, graphs, and tables.\"\"\"\n",
    "    return detect_layout(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a051e846-23e6-46a9-8e1e-c180ff065513",
   "metadata": {},
   "outputs": [],
   "source": [
    "handoff_to_graph = create_handoff_tool(\n",
    "    agent_name=\"GraphAnalysisAgent\",\n",
    "    description=\"If the image contains one or more graphs that require interpretation or chart data extraction, hand over to GraphAnalysisAgent.\"\n",
    ")\n",
    "\n",
    "handoff_to_table = create_handoff_tool(\n",
    "    agent_name=\"TableUnderstandingAgent\",\n",
    "    description=\"If the image contains tables that need parsing into structured format or statistical summary, hand over to TableUnderstandingAgent.\"\n",
    ")\n",
    "\n",
    "layout_agent = create_react_agent(\n",
    "    model,\n",
    "    tools=[layout_analysis, handoff_to_graph, handoff_to_table],\n",
    "    prompt=\"\"\"\n",
    "You are a layout detection agent. Your job is to identify layout components (text, chart, table) from a research poster image.\n",
    "If any graph needs interpretation, hand over to GraphAnalysisAgent.\n",
    "If a table needs parsing or numerical analysis, hand over to TableUnderstandingAgent.\n",
    "\"\"\",\n",
    "    name=\"LayoutAgent\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711318b4-b782-4503-8ef3-f0919080032d",
   "metadata": {},
   "source": [
    "## Graph Analysis Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c9e753b-e6e9-469c-8f35-fdb63be10763",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_chart(image_path: str) -> dict:\n",
    "    \"\"\"\n",
    "    주어진 그래프 이미지에서 데이터 포인트, 축, 레이블 등을 추출하여 반환.\n",
    "    (DePlot 또는 ChartOCR 활용)\n",
    "    \"\"\"\n",
    "    # 예시는 DePlot 기반의 placeholder\n",
    "    return {\n",
    "        \"type\": \"bar\",\n",
    "        \"x_axis\": [\"Q1\", \"Q2\", \"Q3\", \"Q4\"],\n",
    "        \"y_axis_label\": \"Sales (in thousands)\",\n",
    "        \"data\": [120, 100, 80, 130],\n",
    "        \"summary\": \"Sales peaked in Q4, followed by Q1. Lowest in Q3.\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e6c13b1-f7d2-4435-87cf-493676b5f82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def graph_analysis_tool(image_path: str) -> dict:\n",
    "    \"\"\"Analyze the chart in the image and return data points, chart type, and summary.\"\"\"\n",
    "    return analyze_chart(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e4de03-56af-4806-8f59-18eb82bd632a",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_agent = create_react_agent(\n",
    "    model,\n",
    "    tools=[graph_analysis_tool],\n",
    "    prompt=\"\"\"\n",
    "You are a Graph Analysis Agent. Your job is to interpret a graph image and extract the following:\n",
    "- Graph type (bar, line, pie, etc.)\n",
    "- X and Y axis labels\n",
    "- Data points\n",
    "- A natural language summary of the chart\n",
    "\n",
    "Use the tool `graph_analysis_tool` to analyze the graph and return a structured result.\n",
    "\"\"\",\n",
    "    name=\"GraphAnalysisAgent\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b21116b-ddd1-422a-a3c3-09ef28c6731e",
   "metadata": {},
   "source": [
    "## Table Analysis Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e9e6bd-a58e-43af-822a-eb16e6225c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "import cv2\n",
    "\n",
    "def parse_table(image_path: str) -> dict:\n",
    "    \"\"\"\n",
    "    이미지에서 테이블을 OCR 기반으로 구조화하여 파싱\n",
    "    \"\"\"\n",
    "    img = cv2.imread(image_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # OCR 수행\n",
    "    raw_text = pytesseract.image_to_string(gray, config=\"--psm 6\")\n",
    "    \n",
    "    # 예시 파싱 (줄 기준으로 단순 split)\n",
    "    lines = raw_text.strip().split('\\n')\n",
    "    headers = lines[0].split()\n",
    "    rows = [dict(zip(headers, line.split())) for line in lines[1:] if len(line.split()) == len(headers)]\n",
    "    \n",
    "    return {\n",
    "        \"headers\": headers,\n",
    "        \"rows\": rows,\n",
    "        \"summary\": f\"Parsed {len(rows)} rows. Columns: {headers}\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec8cad3-e654-4873-85b6-0951f04ede72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_analysis_tool(image_path: str) -> dict:\n",
    "    \"\"\"Analyze a table image and return structured data and summary statistics.\"\"\"\n",
    "    return parse_table(image_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f72ad1-915e-4aa8-9496-7d7da60dc1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_agent = create_react_agent(\n",
    "    model,\n",
    "    tools=[table_analysis_tool],\n",
    "    prompt=\"\"\"\n",
    "You are a Table Understanding Agent. Your job is to:\n",
    "- Interpret a table image\n",
    "- Return structured rows and columns\n",
    "- Provide a natural language summary such as statistics, patterns, or outliers\n",
    "\n",
    "Use the tool `table_analysis_tool` to analyze the image.\n",
    "\"\"\",\n",
    "    name=\"TableUnderstandingAgent\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94b38df-9710-4151-affc-0d5f95ce2b95",
   "metadata": {},
   "source": [
    "# Text Linking Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8849cd79-65db-4cd7-9bfb-3e467c95c9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def link_text_to_graph(graph_summary: str, text_blocks: list[str]) -> dict:\n",
    "    \"\"\"\n",
    "    그래프 설명 요약과 텍스트 블록 간 연관성 분석\n",
    "    \"\"\"\n",
    "    graph_emb = model.encode(graph_summary, convert_to_tensor=True)\n",
    "    text_embs = model.encode(text_blocks, convert_to_tensor=True)\n",
    "\n",
    "    similarities = util.cos_sim(graph_emb, text_embs)[0]\n",
    "    top_idx = int(similarities.argmax())\n",
    "    top_text = text_blocks[top_idx]\n",
    "    sim_score = float(similarities[top_idx])\n",
    "\n",
    "    return {\n",
    "        \"related_text\": top_text,\n",
    "        \"similarity_score\": round(sim_score, 4),\n",
    "        \"summary\": f\"The most related text is: '{top_text}'\"\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad82a7e-9357-4563-bce9-48e15fd5f61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "\n",
    "@tool\n",
    "def text_linking_tool(inputs: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Link a graph or table to the most related surrounding text.\n",
    "    Expects {\"graph_summary\": \"...\", \"text_blocks\": [...]}\n",
    "    \"\"\"\n",
    "    return link_text_to_graph(inputs[\"graph_summary\"], inputs[\"text_blocks\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bb7fc9-d191-42a2-b6e7-09c22fb5fc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_react_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "text_linking_agent = create_react_agent(\n",
    "    model,\n",
    "    tools=[text_linking_tool],\n",
    "    prompt=\"\"\"\n",
    "You are a Text Linking Agent. You are given:\n",
    "- A summary of a graph or table\n",
    "- A set of text blocks from a research poster\n",
    "\n",
    "Your job is to:\n",
    "- Find the most relevant text block that explains or supports the visual\n",
    "- Provide a natural language explanation of the link\n",
    "\n",
    "Use the tool `text_linking_tool` to perform the match.\n",
    "\"\"\",\n",
    "    name=\"TextLinkingAgent\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537f3204-0f78-403a-bf54-4c984a152b3e",
   "metadata": {},
   "source": [
    "# Analysis Summary Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b7cd19-f6c4-463c-b7f6-c23ae18dd839",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis_summary_tool(inputs: dict) -> str:\n",
    "    \"\"\"\n",
    "    Generate a unified summary from graph and table insights and linked text.\n",
    "    Expects: {\"graphs\": [...], \"tables\": [...]}\n",
    "    \"\"\"\n",
    "    return summarize_analysis(inputs[\"graphs\"], inputs[\"tables\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3707dd20-c726-49f7-9992-f7b759fadf1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_agent = create_react_agent(\n",
    "    model,\n",
    "    tools=[analysis_summary_tool],\n",
    "    prompt=\"\"\"\n",
    "You are a Summary Agent. Your job is to synthesize all the extracted insights from a research poster.\n",
    "You will be given:\n",
    "- Graph summaries with related text\n",
    "- Table summaries with related text\n",
    "\n",
    "Your task is to write a natural language paragraph summarizing the key findings from the poster.\n",
    "Use the `analysis_summary_tool` to perform the final summarization.\n",
    "\"\"\",\n",
    "    name=\"SummaryAgent\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a4d0a6-4f5a-4d33-80bf-53510e31bbc7",
   "metadata": {},
   "source": [
    "## Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be76cb3-e6c3-44a3-8d72-31eb33b52ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_swarm\n",
    "from langgraph.checkpoint import InMemorySaver\n",
    "\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "workflow = create_swarm(\n",
    "    agents=[\n",
    "        layout_agent,\n",
    "        graph_agent,\n",
    "        table_agent,\n",
    "        text_linking_agent,\n",
    "        summary_agent\n",
    "    ],\n",
    "    default_active_agent=\"LayoutAgent\"  # 시작 에이전트\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4f3906-f46a-4d6e-8b7f-344bddfd2e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = workflow.compile(checkpointer=checkpointer)\n",
    "config = {\"configurable\": {\"thread_id\": \"research-poster-1\"}}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
